{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mecab_ver6_2unit实现.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG0GvknErP6B",
        "outputId": "96bff575-ef6f-454f-8b7b-131228572572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mecab-python3\n",
            "  Downloading mecab_python3-1.0.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (574 kB)\n",
            "\u001b[K     |████████████████████████████████| 574 kB 7.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: mecab-python3\n",
            "Successfully installed mecab-python3-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install mecab-python3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipadic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WhaaLritGtt",
        "outputId": "1c9f253e-7186-4b39-9578-c87dee6cd39c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ipadic\n",
            "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.4 MB 7.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: ipadic\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556723 sha256=0a2b84f322e08065f2121621178e21bea7c0c9208e0758504480d3fae571e8e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/8b/99/cf0d27191876637cd3639a560f93aa982d7855ce826c94348b\n",
            "Successfully built ipadic\n",
            "Installing collected packages: ipadic\n",
            "Successfully installed ipadic-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4Q8fP38CRuV",
        "outputId": "e2581c8a-2826-49a5-9f84-8700d5d8f1b0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "# df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "# list=[10,11,15,16]\n",
        "list=[15]\n",
        "df = pd.read_excel(\"./ja_slide9_data.xlsx\", usecols=list,names=['sentence'])\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FHRwCEMrbMG",
        "outputId": "094fd3ea-a179-4489-ccc8-4fd7444ce360"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 133\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              sentence\n",
              "41                                           ベオーバとの差別化\n",
              "27                          インサイトを捉えるトレーニングを実践で積み強化したい\n",
              "70                                  競合品情報を強化したいと考えています\n",
              "73                                      他社品のUUIに対するデータ\n",
              "92   内科の先生はやはり、β3を多く使われてる先生が多い。セカンドチョイスの割合を広げていく点にま...\n",
              "77              製品の情報提供ができているため、しっかりクロージング、処方依頼を強化したい。\n",
              "98                                               競合品情報\n",
              "44                                                特になし\n",
              "38                                        インサイトからの深堀提案\n",
              "103  泌尿器科専門医に対して男性BPH合併OAB患者に対する治療などについてもディスカッション出来..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d7dd3b7-8d8a-46d8-b063-2a243b0666ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>ベオーバとの差別化</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>インサイトを捉えるトレーニングを実践で積み強化したい</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>競合品情報を強化したいと考えています</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>他社品のUUIに対するデータ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>内科の先生はやはり、β3を多く使われてる先生が多い。セカンドチョイスの割合を広げていく点にま...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>製品の情報提供ができているため、しっかりクロージング、処方依頼を強化したい。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>競合品情報</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>特になし</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>インサイトからの深堀提案</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>泌尿器科専門医に対して男性BPH合併OAB患者に対する治療などについてもディスカッション出来...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d7dd3b7-8d8a-46d8-b063-2a243b0666ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3d7dd3b7-8d8a-46d8-b063-2a243b0666ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3d7dd3b7-8d8a-46d8-b063-2a243b0666ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = df.sentence.values\n",
        "print(sentences[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwgY71e-rgC5",
        "outputId": "c7b5fba0-a5a6-4fc2-80cf-4d27ac8ed5ae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "しっかり話し込みが出来た先生には、TOVの効果面や安全性(FORTA等)はお伝えできた。課題は、面会が困難で短時間面会Drや不面Drへの対策が不十分なこと。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col15_sentence=[]\n",
        "\n",
        "for sen in sentences:\n",
        "    col15_sentence.append(sen)\n",
        "col15_sentence_text=''.join(col15_sentence)\n",
        "len(col15_sentence_text)\n",
        "type(col15_sentence_text)\n",
        "# len(col15_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP2Cd1kW09km",
        "outputId": "062d9016-ef64-44c6-94b1-4ed7525b323d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import MeCab\n",
        "import ipadic\n",
        "sentence=col15_sentence_text\n",
        "# sentence = \"AWSの有名なサービスにAmazon Elastic Compute Cloud (EC2) とAmazon Simple Storage Service (S3) がある。これまでのクライアントが保有していた物理的なサーバファームと比較してAWSは大規模な計算処理能力を速やかに提供出来ることが強みである。\"\n",
        "tagger = MeCab.Tagger(ipadic.MECAB_ARGS)\n",
        "word_list=tagger.parse(sentence)\n",
        "# print(word_list)\n",
        "# type(word_list) str"
      ],
      "metadata": {
        "id": "R1nMi1MYrzOg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sentence = \"AWSの有名なサービスにAmazon Elastic Compute Cloud (EC2) とAmazon Simple Storage Service (S3) がある。これまでのクライアントが保有していた物理的なサーバファームと比較してAWSは大規模な計算処理能力を速やかに提供出来ることが強みである。\"\n",
        "# sentence = sentences[5]\n",
        "m = tagger.parseToNode(sentence)\n",
        "\n",
        "keywords = []\n",
        "\n",
        "while m:\n",
        "    if m.feature.split(',')[0] == '名詞':\n",
        "        keywords.append(m.surface)\n",
        "    m = m.next\n",
        "\n",
        "print(keywords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uIX2dj_y8o3",
        "outputId": "4d015047-0a0e-4546-96ed-8dda985f97e4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ベタニスベオーバ', '剤', '理解', 'TOV', '継続', '訴求', '不安', 'イン', 'サイト', '深堀', '重要', 'こと', '着任', '時', '重要', '指導', '現場', 'MR', '今回', 'FFT', 'イン', 'サイト', '深堀', '重要', 'の', 'MR', 'これ', '現場', 'トレーニング', '必要', '先生', 'TOV', '効果', '面', '安全', '性', 'FORTA', '等', '課題', '面会', '困難', '短時間', '面会', 'Dr', '面', 'Dr', '対策', '不十分', 'こと', '3', '一', '選択', 'コリン', '二', '選択', 'OABSS', '排尿', '日誌', '診療', '時間', '問診', '切迫', '性', '尿', '失禁', '有無', '先生', '先生', 'トビ', 'エース', '服用', '患者', 'さん', '像', '一言', 'よう', 'フレーズ', '安全', '性', '質問', 'オブジェクションハンドリング', 'おむつ', 'ケア', '知識', '工夫', '必要', 'Dr', 'イン', 'サイト', '得意', '先', '別', '攻略', '事', '苦手', 'イン', 'サイト', '把握', 'スキル', '身', 'Dr', 'ニーズ', '把握', '位置付け', '確立', 'コリン', '薬', '一', '選択', '処方', '患者', '像', '具体', '的', '提示', 'スライド', 'データ', '疾患', '製品', '知識', '強化', 'TOV', '臨床', '試験', '豊富', '臨床', '試験', '部分', '定期', '的', '復習', 'TOV', 'UUI', '試験', '明確', '疾患', 'スキル', 'GE', '浸食', 'こと', '国策', '抵抗', '事', 'の', 'TOV', '処方', '経験', 'Dｒ', 'コリン', '剤', 'なか', '位置づけ', '場合', '競合', '品', '情報', 'コリン', '薬', 'B', '3', '受容', '体', '作動', '薬', '使い分け', '先生', 'イン', 'サイト', 'スキル', '強化', '競合', '品', 'ベータ', '薬', '訴求', 'ポイント', 'DTL', '内容', 'コリン', '3', '使い分け', 'TOV', '役', '症例', '女性', '意識', 'ほう', 'の', '資材', '予定', '通り', 'リリース', '幸い', 'イン', 'サイト', 'トレーニング', '実践', '強化', '差別', '化', '本日', '実施', 'イン', 'サイト', '確認', '徹底', '作動', '薬', 'TOV', '症例', '作動', '薬', '症例', '明確', 'ポジション', '提示', '理解', '実践', '練習', '必要', 'チーム', 'ミーティング', '等', '復習', '副作用', '対策', 'スライド', 'データ', '教授', 'TOV', '市販', '後', '調査', '結果', '早期', '共有', '活動', '膀胱', '疾患', '関係', '知識', '癌', '領域', '作用', '機', '序', '差別', '化', '徹底', '坑', 'コリン', '剤', '比較', '製品', '知識', 'イン', 'サイト', '深堀', '提案', 'スキル', '松川', '先生', 'BPH', '合併', '試験', 'よう', '試験', 'データ', 'ベオーバ', '差別', '化', 'ベシケア', '差別', '化', 'コリン', 'Fast', '確立', 'スキル', '関連', '情報', '前立腺', '肥大', '症', '知識', '不足', '様々', 'プロービング', '方法', '面談', '際', '適切', 'DSP', 'インパクト', 'ワンポイント', 'メッセージ', '展開', 'よう', '強化', '今月', 'FFT', '様', '製品', '知識', 'プラス', '営業', '必要', 'スキル', '考え方', '研修', '不安', '点', 'クオリティーコール', 'アスキング', '強化', 'DTL', 'スキル', '製品', '知識', '製品', '多く', '泌尿器', '科', '専門医', '夜間', '尿', 'ケース', '3', '流れ', '競合', '品', '情報', '今回', 'FFT', '受講', 'ベシケア', 'TG', '必要', '疾患', '知識', '強豪', '差別', '化', '理解', '他社', '情報', '他', '剤', '違い', '特約', '店', 'MS', '協業', '機会', '創出', '不安', '的', '事', 'の', 'コリン', '薬', '比較', 'DTL', 'TOV', '特性', '虎の巻', '様', 'サマリー', 'ノート', '知識', '確認', 'の', 'ベオーバ', 'データ', 'こと', 'の', 'プロービングスキル', '向上', 'Dr', '耳', '不安', 'UUI', '国内', 'データ', '副作用', '対策', '競合', '品', '情報', '強化', '現場', 'DTL', '話し言葉', '中', '上手', '言い回し', '勉強', 'DTL', 'スキル', '面', '強化', '他社', '品', 'UUI', 'データ', 'DTL', 'スキル', '向上', '3', '作動', '薬', '薬剤', '特性', '理解', '製品', '情報', '提供', 'ため', 'クロージング', '処方', '依頼', '強化', '虎の巻', '他', '剤', '差別', '化', 'TOV', '副作用', '先生', '対応', 'クロージング', '強化', 'TOV', '３', '作動', '薬', '併用', 'データ', '競合', '試験', '復習', '対抗', '品', '選択', '理由', '把握', '対策', '有効', '専門医', '評価', '対策', 'こと', '大事', '競合', '品', '情報', '3', '作動', '薬', '1', 'st', '処方', 'Dr', '自信', 'アプローチ', '方法', '身', 'ベシケア', '対策', '3', '作動', '薬', 'データ', '内科', '先生', '3', '多く', '先生', 'セカンドチョイス', '割合', '点', '不安', 'Dr', 'イン', 'サイト', '製品', 'DTL', '意識', 'DTL', '差別', '化', '排尿', '機能', '障害', '診療', '報酬', '薬物', '療法', '知識', '強化', 'こと', '薬物', '導入', '的確', 'DTL', '可能', 'UUI', '主要', '評価', '項目', 'DTL', '強化', '競合', '品', '情報', '競合', '製品', '情報', '競合', '製品', '知識', 'UUI', '言葉', 'DR', 'MR', '間', '患者', 'さん', '浸透', 'UUI', '言葉', '患者', 'さん', '向け', '啓発', 'お願い', 'Dr', 'イン', 'サイト', 'dtl', '泌尿器', '科', '専門医', '男性', 'BPH', '合併', 'OAB', '患者', '治療', 'ディスカッション', 'よう', '知識', '武装', '疾患', '知識', 'ガイドライン', '位置づけ', '競合', '品', '3', '知識', 'データ', '等', '向上', 'コロナ', '中', 'OAB', '市場', 'Dr', '考え方', 'の', '疾患', '知識', '泌尿器', '科', '領域', '疾患', 'OAB', '以外', '周辺', '知識', 'ONC', '領域', 'がん', '剤', '等', '向上', '事', '専門医', '話題', '関係', '構築', 'TOV', 'の', '製品', '知識', 'OAB', '治療', '薬', 'コリン', '薬', '差別', '化', 'データ', '知識', '面', 'コリン', '3', '作用', '機', '序', '違い', 'コンパクト', '紹介', 'こと', '比較', 'アスキング', 'スキル', 'アップ', '競合', '動き', '有効', '性', '安全', '性', 'バランス', '訴求', '話題', 'ため', 'ネタ', '効果', '時', '対処', '医師', 'ニーズ', 'スキル', '競合', '品', '情報', 'ベオーバ', 'UUI', 'データ', 'TOV', '夜間', '尿', '効果', '活動', '膀胱', '薬剤', '添付', '文書', '上', '違い', '特徴', '明確', '理解', '上', 'TOV', '特性', 'Dr', '合意', '形成', 'アグリー', '確約', '不安', 'イン', 'サイト', 'フレーズ', 'トビ', 'エース', '以外', '後発', '割高', '虎の巻', '他', 'コリン', '薬', '差別', '化', '競合', '品', '情報', '強化', 'イン', 'サイト', '効果', '的', '簡単', '印象', 'イン', 'サイト', '行動', '誰', 'いつ', 'こと', 'チャレンジ', 'CMTEPPV', '供給', '案内', 'TG', 'メッセージ', 'MR', '稼働', '計画', 'リプラン', 'コリン', '薬', '中', '位置づけ', '確認', '積極', '的', '訴求']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(keywords))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCfteukV3q3X",
        "outputId": "769a1fec-a95c-4ba3-a123-722bb121bc9b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stopword():\n",
        "    s=set()\n",
        "    with open('jp_stopwords.txt','r',encoding='UTF-8') as f:\n",
        "        for line in f:\n",
        "            s.add(line.strip())\n",
        "    return s\n",
        "#去停用词\n",
        "def rm_stopwords(text,stopword_list):\n",
        "    s=stopword_list\n",
        "    # text_tokens=text.split()\n",
        "    text_list=[]\n",
        "    #remove stopwords\n",
        "    for word in text:\n",
        "        if word not in s:\n",
        "            text_list.append(word)\n",
        "    return text_list\n",
        "# 去掉文本中的停用词\n",
        "def drop_stopwords(words):\n",
        "    import itertools\n",
        "    content_dropped=[word for word in words if word not in stopword]\n",
        "    content=''.join(list(itertools.chain(*content_dropped)))\n",
        "    return content\n",
        "\n",
        "stopword=get_stopword()\n",
        "contents=rm_stopwords(keywords,stopword)\n",
        "contents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JYTHz1t2CtO",
        "outputId": "66c57122-970e-4011-b7d0-3848842a602c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ベタニスベオーバ',\n",
              " '剤',\n",
              " '理解',\n",
              " 'TOV',\n",
              " '継続',\n",
              " '訴求',\n",
              " '不安',\n",
              " 'イン',\n",
              " 'サイト',\n",
              " '深堀',\n",
              " '重要',\n",
              " 'こと',\n",
              " '着任',\n",
              " '時',\n",
              " '重要',\n",
              " '指導',\n",
              " '現場',\n",
              " 'MR',\n",
              " '今回',\n",
              " 'FFT',\n",
              " 'イン',\n",
              " 'サイト',\n",
              " '深堀',\n",
              " '重要',\n",
              " 'MR',\n",
              " '現場',\n",
              " 'トレーニング',\n",
              " '必要',\n",
              " '先生',\n",
              " 'TOV',\n",
              " '効果',\n",
              " '面',\n",
              " '安全',\n",
              " '性',\n",
              " 'FORTA',\n",
              " '等',\n",
              " '課題',\n",
              " '面会',\n",
              " '困難',\n",
              " '短時間',\n",
              " '面会',\n",
              " 'Dr',\n",
              " '面',\n",
              " 'Dr',\n",
              " '対策',\n",
              " '不十分',\n",
              " 'こと',\n",
              " '3',\n",
              " '一',\n",
              " '選択',\n",
              " 'コリン',\n",
              " '二',\n",
              " '選択',\n",
              " 'OABSS',\n",
              " '排尿',\n",
              " '日誌',\n",
              " '診療',\n",
              " '時間',\n",
              " '問診',\n",
              " '切迫',\n",
              " '性',\n",
              " '尿',\n",
              " '失禁',\n",
              " '有無',\n",
              " '先生',\n",
              " '先生',\n",
              " 'トビ',\n",
              " 'エース',\n",
              " '服用',\n",
              " '患者',\n",
              " 'さん',\n",
              " '像',\n",
              " '一言',\n",
              " 'よう',\n",
              " 'フレーズ',\n",
              " '安全',\n",
              " '性',\n",
              " '質問',\n",
              " 'オブジェクションハンドリング',\n",
              " 'おむつ',\n",
              " 'ケア',\n",
              " '知識',\n",
              " '工夫',\n",
              " '必要',\n",
              " 'Dr',\n",
              " 'イン',\n",
              " 'サイト',\n",
              " '得意',\n",
              " '先',\n",
              " '別',\n",
              " '攻略',\n",
              " '事',\n",
              " '苦手',\n",
              " 'イン',\n",
              " 'サイト',\n",
              " '把握',\n",
              " 'スキル',\n",
              " '身',\n",
              " 'Dr',\n",
              " 'ニーズ',\n",
              " '把握',\n",
              " '位置付け',\n",
              " '確立',\n",
              " 'コリン',\n",
              " '薬',\n",
              " '一',\n",
              " '選択',\n",
              " '処方',\n",
              " '患者',\n",
              " '像',\n",
              " '具体',\n",
              " '的',\n",
              " '提示',\n",
              " 'スライド',\n",
              " 'データ',\n",
              " '疾患',\n",
              " '製品',\n",
              " '知識',\n",
              " '強化',\n",
              " 'TOV',\n",
              " '臨床',\n",
              " '試験',\n",
              " '豊富',\n",
              " '臨床',\n",
              " '試験',\n",
              " '部分',\n",
              " '定期',\n",
              " '的',\n",
              " '復習',\n",
              " 'TOV',\n",
              " 'UUI',\n",
              " '試験',\n",
              " '明確',\n",
              " '疾患',\n",
              " 'スキル',\n",
              " 'GE',\n",
              " '浸食',\n",
              " 'こと',\n",
              " '国策',\n",
              " '抵抗',\n",
              " '事',\n",
              " 'TOV',\n",
              " '処方',\n",
              " '経験',\n",
              " 'Dｒ',\n",
              " 'コリン',\n",
              " '剤',\n",
              " 'なか',\n",
              " '位置づけ',\n",
              " '場合',\n",
              " '競合',\n",
              " '品',\n",
              " '情報',\n",
              " 'コリン',\n",
              " '薬',\n",
              " 'B',\n",
              " '3',\n",
              " '受容',\n",
              " '体',\n",
              " '作動',\n",
              " '薬',\n",
              " '使い分け',\n",
              " '先生',\n",
              " 'イン',\n",
              " 'サイト',\n",
              " 'スキル',\n",
              " '強化',\n",
              " '競合',\n",
              " '品',\n",
              " 'ベータ',\n",
              " '薬',\n",
              " '訴求',\n",
              " 'ポイント',\n",
              " 'DTL',\n",
              " '内容',\n",
              " 'コリン',\n",
              " '3',\n",
              " '使い分け',\n",
              " 'TOV',\n",
              " '役',\n",
              " '症例',\n",
              " '女性',\n",
              " '意識',\n",
              " 'ほう',\n",
              " '資材',\n",
              " '予定',\n",
              " '通り',\n",
              " 'リリース',\n",
              " '幸い',\n",
              " 'イン',\n",
              " 'サイト',\n",
              " 'トレーニング',\n",
              " '実践',\n",
              " '強化',\n",
              " '差別',\n",
              " '化',\n",
              " '本日',\n",
              " '実施',\n",
              " 'イン',\n",
              " 'サイト',\n",
              " '確認',\n",
              " '徹底',\n",
              " '作動',\n",
              " '薬',\n",
              " 'TOV',\n",
              " '症例',\n",
              " '作動',\n",
              " '薬',\n",
              " '症例',\n",
              " '明確',\n",
              " 'ポジション',\n",
              " '提示',\n",
              " '理解',\n",
              " '実践',\n",
              " '練習',\n",
              " '必要',\n",
              " 'チーム',\n",
              " 'ミーティング',\n",
              " '等',\n",
              " '復習',\n",
              " '副作用',\n",
              " '対策',\n",
              " 'スライド',\n",
              " 'データ',\n",
              " '教授',\n",
              " 'TOV',\n",
              " '市販',\n",
              " '後',\n",
              " '調査',\n",
              " '結果',\n",
              " '早期',\n",
              " '共有',\n",
              " '活動',\n",
              " '膀胱',\n",
              " '疾患',\n",
              " '関係',\n",
              " '知識',\n",
              " '癌',\n",
              " '領域',\n",
              " '作用',\n",
              " '機',\n",
              " '序',\n",
              " '差別',\n",
              " '化',\n",
              " '徹底',\n",
              " '坑',\n",
              " 'コリン',\n",
              " '剤',\n",
              " '比較',\n",
              " '製品',\n",
              " '知識',\n",
              " 'イン',\n",
              " 'サイト',\n",
              " '深堀',\n",
              " '提案',\n",
              " 'スキル',\n",
              " '松川',\n",
              " '先生',\n",
              " 'BPH',\n",
              " '合併',\n",
              " '試験',\n",
              " 'よう',\n",
              " '試験',\n",
              " 'データ',\n",
              " 'ベオーバ',\n",
              " '差別',\n",
              " '化',\n",
              " 'ベシケア',\n",
              " '差別',\n",
              " '化',\n",
              " 'コリン',\n",
              " 'Fast',\n",
              " '確立',\n",
              " 'スキル',\n",
              " '関連',\n",
              " '情報',\n",
              " '前立腺',\n",
              " '肥大',\n",
              " '症',\n",
              " '知識',\n",
              " '不足',\n",
              " '様々',\n",
              " 'プロービング',\n",
              " '方法',\n",
              " '面談',\n",
              " '際',\n",
              " '適切',\n",
              " 'DSP',\n",
              " 'インパクト',\n",
              " 'ワンポイント',\n",
              " 'メッセージ',\n",
              " '展開',\n",
              " 'よう',\n",
              " '強化',\n",
              " '今月',\n",
              " 'FFT',\n",
              " '様',\n",
              " '製品',\n",
              " '知識',\n",
              " 'プラス',\n",
              " '営業',\n",
              " '必要',\n",
              " 'スキル',\n",
              " '考え方',\n",
              " '研修',\n",
              " '不安',\n",
              " '点',\n",
              " 'クオリティーコール',\n",
              " 'アスキング',\n",
              " '強化',\n",
              " 'DTL',\n",
              " 'スキル',\n",
              " '製品',\n",
              " '知識',\n",
              " '製品',\n",
              " '多く',\n",
              " '泌尿器',\n",
              " '科',\n",
              " '専門医',\n",
              " '夜間',\n",
              " '尿',\n",
              " 'ケース',\n",
              " '3',\n",
              " '流れ',\n",
              " '競合',\n",
              " '品',\n",
              " '情報',\n",
              " '今回',\n",
              " 'FFT',\n",
              " '受講',\n",
              " 'ベシケア',\n",
              " 'TG',\n",
              " '必要',\n",
              " '疾患',\n",
              " '知識',\n",
              " '強豪',\n",
              " '差別',\n",
              " '化',\n",
              " '理解',\n",
              " '他社',\n",
              " '情報',\n",
              " '他',\n",
              " '剤',\n",
              " '違い',\n",
              " '特約',\n",
              " '店',\n",
              " 'MS',\n",
              " '協業',\n",
              " '機会',\n",
              " '創出',\n",
              " '不安',\n",
              " '的',\n",
              " '事',\n",
              " 'コリン',\n",
              " '薬',\n",
              " '比較',\n",
              " 'DTL',\n",
              " 'TOV',\n",
              " '特性',\n",
              " '虎の巻',\n",
              " '様',\n",
              " 'サマリー',\n",
              " 'ノート',\n",
              " '知識',\n",
              " '確認',\n",
              " 'ベオーバ',\n",
              " 'データ',\n",
              " 'こと',\n",
              " 'プロービングスキル',\n",
              " '向上',\n",
              " 'Dr',\n",
              " '耳',\n",
              " '不安',\n",
              " 'UUI',\n",
              " '国内',\n",
              " 'データ',\n",
              " '副作用',\n",
              " '対策',\n",
              " '競合',\n",
              " '品',\n",
              " '情報',\n",
              " '強化',\n",
              " '現場',\n",
              " 'DTL',\n",
              " '話し言葉',\n",
              " '中',\n",
              " '上手',\n",
              " '言い回し',\n",
              " '勉強',\n",
              " 'DTL',\n",
              " 'スキル',\n",
              " '面',\n",
              " '強化',\n",
              " '他社',\n",
              " '品',\n",
              " 'UUI',\n",
              " 'データ',\n",
              " 'DTL',\n",
              " 'スキル',\n",
              " '向上',\n",
              " '3',\n",
              " '作動',\n",
              " '薬',\n",
              " '薬剤',\n",
              " '特性',\n",
              " '理解',\n",
              " '製品',\n",
              " '情報',\n",
              " '提供',\n",
              " 'ため',\n",
              " 'クロージング',\n",
              " '処方',\n",
              " '依頼',\n",
              " '強化',\n",
              " '虎の巻',\n",
              " '他',\n",
              " '剤',\n",
              " '差別',\n",
              " '化',\n",
              " 'TOV',\n",
              " '副作用',\n",
              " '先生',\n",
              " '対応',\n",
              " 'クロージング',\n",
              " '強化',\n",
              " 'TOV',\n",
              " '３',\n",
              " '作動',\n",
              " '薬',\n",
              " '併用',\n",
              " 'データ',\n",
              " '競合',\n",
              " '試験',\n",
              " '復習',\n",
              " '対抗',\n",
              " '品',\n",
              " '選択',\n",
              " '理由',\n",
              " '把握',\n",
              " '対策',\n",
              " '有効',\n",
              " '専門医',\n",
              " '評価',\n",
              " '対策',\n",
              " 'こと',\n",
              " '大事',\n",
              " '競合',\n",
              " '品',\n",
              " '情報',\n",
              " '3',\n",
              " '作動',\n",
              " '薬',\n",
              " '1',\n",
              " 'st',\n",
              " '処方',\n",
              " 'Dr',\n",
              " '自信',\n",
              " 'アプローチ',\n",
              " '方法',\n",
              " '身',\n",
              " 'ベシケア',\n",
              " '対策',\n",
              " '3',\n",
              " '作動',\n",
              " '薬',\n",
              " 'データ',\n",
              " '内科',\n",
              " '先生',\n",
              " '3',\n",
              " '多く',\n",
              " '先生',\n",
              " 'セカンドチョイス',\n",
              " '割合',\n",
              " '点',\n",
              " '不安',\n",
              " 'Dr',\n",
              " 'イン',\n",
              " 'サイト',\n",
              " '製品',\n",
              " 'DTL',\n",
              " '意識',\n",
              " 'DTL',\n",
              " '差別',\n",
              " '化',\n",
              " '排尿',\n",
              " '機能',\n",
              " '障害',\n",
              " '診療',\n",
              " '報酬',\n",
              " '薬物',\n",
              " '療法',\n",
              " '知識',\n",
              " '強化',\n",
              " 'こと',\n",
              " '薬物',\n",
              " '導入',\n",
              " '的確',\n",
              " 'DTL',\n",
              " '可能',\n",
              " 'UUI',\n",
              " '主要',\n",
              " '評価',\n",
              " '項目',\n",
              " 'DTL',\n",
              " '強化',\n",
              " '競合',\n",
              " '品',\n",
              " '情報',\n",
              " '競合',\n",
              " '製品',\n",
              " '情報',\n",
              " '競合',\n",
              " '製品',\n",
              " '知識',\n",
              " 'UUI',\n",
              " '言葉',\n",
              " 'DR',\n",
              " 'MR',\n",
              " '間',\n",
              " '患者',\n",
              " 'さん',\n",
              " '浸透',\n",
              " 'UUI',\n",
              " '言葉',\n",
              " '患者',\n",
              " 'さん',\n",
              " '向け',\n",
              " '啓発',\n",
              " 'お願い',\n",
              " 'Dr',\n",
              " 'イン',\n",
              " 'サイト',\n",
              " 'dtl',\n",
              " '泌尿器',\n",
              " '科',\n",
              " '専門医',\n",
              " '男性',\n",
              " 'BPH',\n",
              " '合併',\n",
              " 'OAB',\n",
              " '患者',\n",
              " '治療',\n",
              " 'ディスカッション',\n",
              " 'よう',\n",
              " '知識',\n",
              " '武装',\n",
              " '疾患',\n",
              " '知識',\n",
              " 'ガイドライン',\n",
              " '位置づけ',\n",
              " '競合',\n",
              " '品',\n",
              " '3',\n",
              " '知識',\n",
              " 'データ',\n",
              " '等',\n",
              " '向上',\n",
              " 'コロナ',\n",
              " '中',\n",
              " 'OAB',\n",
              " '市場',\n",
              " 'Dr',\n",
              " '考え方',\n",
              " '疾患',\n",
              " '知識',\n",
              " '泌尿器',\n",
              " '科',\n",
              " '領域',\n",
              " '疾患',\n",
              " 'OAB',\n",
              " '以外',\n",
              " '周辺',\n",
              " '知識',\n",
              " 'ONC',\n",
              " '領域',\n",
              " 'がん',\n",
              " '剤',\n",
              " '等',\n",
              " '向上',\n",
              " '事',\n",
              " '専門医',\n",
              " '話題',\n",
              " '関係',\n",
              " '構築',\n",
              " 'TOV',\n",
              " '製品',\n",
              " '知識',\n",
              " 'OAB',\n",
              " '治療',\n",
              " '薬',\n",
              " 'コリン',\n",
              " '薬',\n",
              " '差別',\n",
              " '化',\n",
              " 'データ',\n",
              " '知識',\n",
              " '面',\n",
              " 'コリン',\n",
              " '3',\n",
              " '作用',\n",
              " '機',\n",
              " '序',\n",
              " '違い',\n",
              " 'コンパクト',\n",
              " '紹介',\n",
              " 'こと',\n",
              " '比較',\n",
              " 'アスキング',\n",
              " 'スキル',\n",
              " 'アップ',\n",
              " '競合',\n",
              " '動き',\n",
              " '有効',\n",
              " '性',\n",
              " '安全',\n",
              " '性',\n",
              " 'バランス',\n",
              " '訴求',\n",
              " '話題',\n",
              " 'ため',\n",
              " 'ネタ',\n",
              " '効果',\n",
              " '時',\n",
              " '対処',\n",
              " '医師',\n",
              " 'ニーズ',\n",
              " 'スキル',\n",
              " '競合',\n",
              " '品',\n",
              " '情報',\n",
              " 'ベオーバ',\n",
              " 'UUI',\n",
              " 'データ',\n",
              " 'TOV',\n",
              " '夜間',\n",
              " '尿',\n",
              " '効果',\n",
              " '活動',\n",
              " '膀胱',\n",
              " '薬剤',\n",
              " '添付',\n",
              " '文書',\n",
              " '上',\n",
              " '違い',\n",
              " '特徴',\n",
              " '明確',\n",
              " '理解',\n",
              " '上',\n",
              " 'TOV',\n",
              " '特性',\n",
              " 'Dr',\n",
              " '合意',\n",
              " '形成',\n",
              " 'アグリー',\n",
              " '確約',\n",
              " '不安',\n",
              " 'イン',\n",
              " 'サイト',\n",
              " 'フレーズ',\n",
              " 'トビ',\n",
              " 'エース',\n",
              " '以外',\n",
              " '後発',\n",
              " '割高',\n",
              " '虎の巻',\n",
              " '他',\n",
              " 'コリン',\n",
              " '薬',\n",
              " '差別',\n",
              " '化',\n",
              " '競合',\n",
              " '品',\n",
              " '情報',\n",
              " '強化',\n",
              " 'イン',\n",
              " 'サイト',\n",
              " '効果',\n",
              " '的',\n",
              " '簡単',\n",
              " '印象',\n",
              " 'イン',\n",
              " 'サイト',\n",
              " '行動',\n",
              " '誰',\n",
              " 'いつ',\n",
              " 'こと',\n",
              " 'チャレンジ',\n",
              " 'CMTEPPV',\n",
              " '供給',\n",
              " '案内',\n",
              " 'TG',\n",
              " 'メッセージ',\n",
              " 'MR',\n",
              " '稼働',\n",
              " '計画',\n",
              " 'リプラン',\n",
              " 'コリン',\n",
              " '薬',\n",
              " '中',\n",
              " '位置づけ',\n",
              " '確認',\n",
              " '積極',\n",
              " '的',\n",
              " '訴求']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(contents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDCEyIMZ3Maf",
        "outputId": "02f0cf68-87bc-4473-eb0d-3f14d61d949f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 词频"
      ],
      "metadata": {
        "id": "UVr_t9zst15e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import *\n",
        "mpl.rcParams['font.sans-serif']=['SimHei']\n",
        "\n",
        "def word_freq(fenci_con,n=5):#n表示出现次数最多的前n项\n",
        "    c=Counter(fenci_con)\n",
        "    d=dict(c.most_common(n))\n",
        "    # print(d)\n",
        "    # plt.figure(figsize=(15,5))\n",
        "    # plt.bar(d.keys(),d.values())\n",
        "    return d"
      ],
      "metadata": {
        "id": "-x8XHntfty-T"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_common_words=word_freq(contents,n=20)\n",
        "print(most_common_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zLyS-fJuBcN",
        "outputId": "50b698a6-9c91-477e-f7cd-8b6664934978"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'知識': 18, '薬': 15, 'TOV': 14, 'イン': 13, 'サイト': 13, '競合': 13, 'コリン': 12, '強化': 12, 'スキル': 11, 'データ': 11, '品': 11, '情報': 11, 'Dr': 10, '3': 10, '製品': 10, 'DTL': 10, '差別': 9, '化': 9, 'こと': 8, '先生': 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keysList = [key for key in most_common_words]\n",
        "print(keysList)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da2X776vSAA7",
        "outputId": "d91740a0-dac3-4b99-b69d-7f54d386137a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['知識', '薬', 'TOV', 'イン', 'サイト', '競合', 'コリン', '強化', 'スキル', 'データ', '品', '情報', 'Dr', '3', '製品', 'DTL', '差別', '化', 'こと', '先生']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import permutations\n",
        "# list=['a','b','c']\n",
        "list=keysList\n",
        "w_2=permutations(list,2)\n",
        "y = [''.join(i) for i in w_2]\n",
        "print(y)\n",
        "# w_2=list(itertools.combinations(list,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x_iyxIjNQxj",
        "outputId": "103472a6-c18e-440e-a3e3-77a11ec50390"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['知識薬', '知識TOV', '知識イン', '知識サイト', '知識競合', '知識コリン', '知識強化', '知識スキル', '知識データ', '知識品', '知識情報', '知識Dr', '知識3', '知識製品', '知識DTL', '知識差別', '知識化', '知識こと', '知識先生', '薬知識', '薬TOV', '薬イン', '薬サイト', '薬競合', '薬コリン', '薬強化', '薬スキル', '薬データ', '薬品', '薬情報', '薬Dr', '薬3', '薬製品', '薬DTL', '薬差別', '薬化', '薬こと', '薬先生', 'TOV知識', 'TOV薬', 'TOVイン', 'TOVサイト', 'TOV競合', 'TOVコリン', 'TOV強化', 'TOVスキル', 'TOVデータ', 'TOV品', 'TOV情報', 'TOVDr', 'TOV3', 'TOV製品', 'TOVDTL', 'TOV差別', 'TOV化', 'TOVこと', 'TOV先生', 'イン知識', 'イン薬', 'インTOV', 'インサイト', 'イン競合', 'インコリン', 'イン強化', 'インスキル', 'インデータ', 'イン品', 'イン情報', 'インDr', 'イン3', 'イン製品', 'インDTL', 'イン差別', 'イン化', 'インこと', 'イン先生', 'サイト知識', 'サイト薬', 'サイトTOV', 'サイトイン', 'サイト競合', 'サイトコリン', 'サイト強化', 'サイトスキル', 'サイトデータ', 'サイト品', 'サイト情報', 'サイトDr', 'サイト3', 'サイト製品', 'サイトDTL', 'サイト差別', 'サイト化', 'サイトこと', 'サイト先生', '競合知識', '競合薬', '競合TOV', '競合イン', '競合サイト', '競合コリン', '競合強化', '競合スキル', '競合データ', '競合品', '競合情報', '競合Dr', '競合3', '競合製品', '競合DTL', '競合差別', '競合化', '競合こと', '競合先生', 'コリン知識', 'コリン薬', 'コリンTOV', 'コリンイン', 'コリンサイト', 'コリン競合', 'コリン強化', 'コリンスキル', 'コリンデータ', 'コリン品', 'コリン情報', 'コリンDr', 'コリン3', 'コリン製品', 'コリンDTL', 'コリン差別', 'コリン化', 'コリンこと', 'コリン先生', '強化知識', '強化薬', '強化TOV', '強化イン', '強化サイト', '強化競合', '強化コリン', '強化スキル', '強化データ', '強化品', '強化情報', '強化Dr', '強化3', '強化製品', '強化DTL', '強化差別', '強化化', '強化こと', '強化先生', 'スキル知識', 'スキル薬', 'スキルTOV', 'スキルイン', 'スキルサイト', 'スキル競合', 'スキルコリン', 'スキル強化', 'スキルデータ', 'スキル品', 'スキル情報', 'スキルDr', 'スキル3', 'スキル製品', 'スキルDTL', 'スキル差別', 'スキル化', 'スキルこと', 'スキル先生', 'データ知識', 'データ薬', 'データTOV', 'データイン', 'データサイト', 'データ競合', 'データコリン', 'データ強化', 'データスキル', 'データ品', 'データ情報', 'データDr', 'データ3', 'データ製品', 'データDTL', 'データ差別', 'データ化', 'データこと', 'データ先生', '品知識', '品薬', '品TOV', '品イン', '品サイト', '品競合', '品コリン', '品強化', '品スキル', '品データ', '品情報', '品Dr', '品3', '品製品', '品DTL', '品差別', '品化', '品こと', '品先生', '情報知識', '情報薬', '情報TOV', '情報イン', '情報サイト', '情報競合', '情報コリン', '情報強化', '情報スキル', '情報データ', '情報品', '情報Dr', '情報3', '情報製品', '情報DTL', '情報差別', '情報化', '情報こと', '情報先生', 'Dr知識', 'Dr薬', 'DrTOV', 'Drイン', 'Drサイト', 'Dr競合', 'Drコリン', 'Dr強化', 'Drスキル', 'Drデータ', 'Dr品', 'Dr情報', 'Dr3', 'Dr製品', 'DrDTL', 'Dr差別', 'Dr化', 'Drこと', 'Dr先生', '3知識', '3薬', '3TOV', '3イン', '3サイト', '3競合', '3コリン', '3強化', '3スキル', '3データ', '3品', '3情報', '3Dr', '3製品', '3DTL', '3差別', '3化', '3こと', '3先生', '製品知識', '製品薬', '製品TOV', '製品イン', '製品サイト', '製品競合', '製品コリン', '製品強化', '製品スキル', '製品データ', '製品品', '製品情報', '製品Dr', '製品3', '製品DTL', '製品差別', '製品化', '製品こと', '製品先生', 'DTL知識', 'DTL薬', 'DTLTOV', 'DTLイン', 'DTLサイト', 'DTL競合', 'DTLコリン', 'DTL強化', 'DTLスキル', 'DTLデータ', 'DTL品', 'DTL情報', 'DTLDr', 'DTL3', 'DTL製品', 'DTL差別', 'DTL化', 'DTLこと', 'DTL先生', '差別知識', '差別薬', '差別TOV', '差別イン', '差別サイト', '差別競合', '差別コリン', '差別強化', '差別スキル', '差別データ', '差別品', '差別情報', '差別Dr', '差別3', '差別製品', '差別DTL', '差別化', '差別こと', '差別先生', '化知識', '化薬', '化TOV', '化イン', '化サイト', '化競合', '化コリン', '化強化', '化スキル', '化データ', '化品', '化情報', '化Dr', '化3', '化製品', '化DTL', '化差別', '化こと', '化先生', 'こと知識', 'こと薬', 'ことTOV', 'ことイン', 'ことサイト', 'こと競合', 'ことコリン', 'こと強化', 'ことスキル', 'ことデータ', 'こと品', 'こと情報', 'ことDr', 'こと3', 'こと製品', 'ことDTL', 'こと差別', 'こと化', 'こと先生', '先生知識', '先生薬', '先生TOV', '先生イン', '先生サイト', '先生競合', '先生コリン', '先生強化', '先生スキル', '先生データ', '先生品', '先生情報', '先生Dr', '先生3', '先生製品', '先生DTL', '先生差別', '先生化', '先生こと']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# string = \"This contains a word\"\n",
        "\n",
        "def unit2_dictionary(str,word_list):\n",
        "    counts = dict()\n",
        "    for word in word_list:\n",
        "        dic=str.count(word)\n",
        "        # counts[word] =dic\n",
        "        if dic!=0:\n",
        "            counts[word] =dic\n",
        "\n",
        "    return counts\n",
        "unit2_dic=unit2_dictionary(col15_sentence_text,y)\n",
        "print(unit2_dic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puSlXa8t3o7G",
        "outputId": "96f0db54-b17b-496c-f5bb-d0c0199e0f44"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'知識イン': 1, '知識製品': 1, 'インサイト': 13, '競合品': 9, '競合製品': 1, 'コリン薬': 6, '強化TOV': 1, 'スキル競合': 1, 'データ競合': 1, '品知識': 5, '品情報': 8, '品DTL': 1, '情報競合': 2, 'Drイン': 1, '製品知識': 5, '製品情報': 1, '製品DTL': 1, 'DTLスキル': 3, '差別化': 9, '化TOV': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict1 = unit2_dic\n",
        "sorted_dict = {}\n",
        "sorted_keys = sorted(dict1, key=dict1.get,reverse=True)  # [1, 3, 2]\n",
        "\n",
        "for w in sorted_keys:\n",
        "    sorted_dict[w] = dict1[w]\n",
        "\n",
        "print(sorted_dict) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjNF_FXL5fMk",
        "outputId": "9de0350f-0c16-41f0-ac6d-bffb2d1080e1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'インサイト': 13, '競合品': 9, '差別化': 9, '品情報': 8, 'コリン薬': 6, '品知識': 5, '製品知識': 5, 'DTLスキル': 3, '情報競合': 2, '化TOV': 2, '知識イン': 1, '知識製品': 1, '競合製品': 1, '強化TOV': 1, 'スキル競合': 1, 'データ競合': 1, '品DTL': 1, 'Drイン': 1, '製品情報': 1, '製品DTL': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HbFTXeDx1I9",
        "outputId": "1438da9e-9d17-4cf4-9920-03aa8be58aae"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "380"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = dict()\n",
        "dic=col15_sentence_text.count(y[2])\n",
        "if dic!=0:\n",
        "    counts[y[2]] =dic\n",
        "counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KGWqTOqybLF",
        "outputId": "80477d48-68ae-43ea-c429-03a2cf6c7264"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'知識イン': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import combinations\n",
        "from itertools import permutations\n",
        "list=['a','b','c']\n",
        "w_2=combinations(list,2)\n",
        "y = [''.join(i) for i in w_2]\n",
        "w_2_1=permutations(list,2)\n",
        "z = [''.join(i) for i in w_2_1]\n",
        "print(y)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXdMovAtUm2c",
        "outputId": "b7430186-2b73-4c6d-b1fd-d73bc88746dc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ab', 'ac', 'bc']\n",
            "['ab', 'ac', 'ba', 'bc', 'ca', 'cb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# string = \"This contains a word\"\n",
        "unit2_dic={}\n",
        "for i in range(len(y)):\n",
        "    frequency=0\n",
        "    if y[i] in col15_sentence_text:\n",
        "        frequency+=1\n",
        "        unit2_dic[y[i]] =frequency\n",
        "    else:\n",
        "        unit2_dic[y[i]] =frequency\n",
        "print(unit2_dic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H_fgRoThVax",
        "outputId": "924a02f8-625c-42b2-b842-54ac2ba904fb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'知識薬': 0, '知識TOV': 0, '知識イン': 1, '知識サイト': 0, '知識競合': 0, '知識コリン': 0, '知識強化': 0, '知識スキル': 0, '知識データ': 0, '知識品': 0, '知識情報': 0, '知識Dr': 0, '知識3': 0, '知識製品': 1, '知識DTL': 0, '知識差別': 0, '知識化': 0, '知識こと': 0, '知識先生': 0, '薬知識': 0, '薬TOV': 0, '薬イン': 0, '薬サイト': 0, '薬競合': 0, '薬コリン': 0, '薬強化': 0, '薬スキル': 0, '薬データ': 0, '薬品': 0, '薬情報': 0, '薬Dr': 0, '薬3': 0, '薬製品': 0, '薬DTL': 0, '薬差別': 0, '薬化': 0, '薬こと': 0, '薬先生': 0, 'TOV知識': 0, 'TOV薬': 0, 'TOVイン': 0, 'TOVサイト': 0, 'TOV競合': 0, 'TOVコリン': 0, 'TOV強化': 0, 'TOVスキル': 0, 'TOVデータ': 0, 'TOV品': 0, 'TOV情報': 0, 'TOVDr': 0, 'TOV3': 0, 'TOV製品': 0, 'TOVDTL': 0, 'TOV差別': 0, 'TOV化': 0, 'TOVこと': 0, 'TOV先生': 0, 'イン知識': 0, 'イン薬': 0, 'インTOV': 0, 'インサイト': 1, 'イン競合': 0, 'インコリン': 0, 'イン強化': 0, 'インスキル': 0, 'インデータ': 0, 'イン品': 0, 'イン情報': 0, 'インDr': 0, 'イン3': 0, 'イン製品': 0, 'インDTL': 0, 'イン差別': 0, 'イン化': 0, 'インこと': 0, 'イン先生': 0, 'サイト知識': 0, 'サイト薬': 0, 'サイトTOV': 0, 'サイトイン': 0, 'サイト競合': 0, 'サイトコリン': 0, 'サイト強化': 0, 'サイトスキル': 0, 'サイトデータ': 0, 'サイト品': 0, 'サイト情報': 0, 'サイトDr': 0, 'サイト3': 0, 'サイト製品': 0, 'サイトDTL': 0, 'サイト差別': 0, 'サイト化': 0, 'サイトこと': 0, 'サイト先生': 0, '競合知識': 0, '競合薬': 0, '競合TOV': 0, '競合イン': 0, '競合サイト': 0, '競合コリン': 0, '競合強化': 0, '競合スキル': 0, '競合データ': 0, '競合品': 1, '競合情報': 0, '競合Dr': 0, '競合3': 0, '競合製品': 1, '競合DTL': 0, '競合差別': 0, '競合化': 0, '競合こと': 0, '競合先生': 0, 'コリン知識': 0, 'コリン薬': 1, 'コリンTOV': 0, 'コリンイン': 0, 'コリンサイト': 0, 'コリン競合': 0, 'コリン強化': 0, 'コリンスキル': 0, 'コリンデータ': 0, 'コリン品': 0, 'コリン情報': 0, 'コリンDr': 0, 'コリン3': 0, 'コリン製品': 0, 'コリンDTL': 0, 'コリン差別': 0, 'コリン化': 0, 'コリンこと': 0, 'コリン先生': 0, '強化知識': 0, '強化薬': 0, '強化TOV': 1, '強化イン': 0, '強化サイト': 0, '強化競合': 0, '強化コリン': 0, '強化スキル': 0, '強化データ': 0, '強化品': 0, '強化情報': 0, '強化Dr': 0, '強化3': 0, '強化製品': 0, '強化DTL': 0, '強化差別': 0, '強化化': 0, '強化こと': 0, '強化先生': 0, 'スキル知識': 0, 'スキル薬': 0, 'スキルTOV': 0, 'スキルイン': 0, 'スキルサイト': 0, 'スキル競合': 1, 'スキルコリン': 0, 'スキル強化': 0, 'スキルデータ': 0, 'スキル品': 0, 'スキル情報': 0, 'スキルDr': 0, 'スキル3': 0, 'スキル製品': 0, 'スキルDTL': 0, 'スキル差別': 0, 'スキル化': 0, 'スキルこと': 0, 'スキル先生': 0, 'データ知識': 0, 'データ薬': 0, 'データTOV': 0, 'データイン': 0, 'データサイト': 0, 'データ競合': 1, 'データコリン': 0, 'データ強化': 0, 'データスキル': 0, 'データ品': 0, 'データ情報': 0, 'データDr': 0, 'データ3': 0, 'データ製品': 0, 'データDTL': 0, 'データ差別': 0, 'データ化': 0, 'データこと': 0, 'データ先生': 0, '品知識': 1, '品薬': 0, '品TOV': 0, '品イン': 0, '品サイト': 0, '品競合': 0, '品コリン': 0, '品強化': 0, '品スキル': 0, '品データ': 0, '品情報': 1, '品Dr': 0, '品3': 0, '品製品': 0, '品DTL': 1, '品差別': 0, '品化': 0, '品こと': 0, '品先生': 0, '情報知識': 0, '情報薬': 0, '情報TOV': 0, '情報イン': 0, '情報サイト': 0, '情報競合': 1, '情報コリン': 0, '情報強化': 0, '情報スキル': 0, '情報データ': 0, '情報品': 0, '情報Dr': 0, '情報3': 0, '情報製品': 0, '情報DTL': 0, '情報差別': 0, '情報化': 0, '情報こと': 0, '情報先生': 0, 'Dr知識': 0, 'Dr薬': 0, 'DrTOV': 0, 'Drイン': 1, 'Drサイト': 0, 'Dr競合': 0, 'Drコリン': 0, 'Dr強化': 0, 'Drスキル': 0, 'Drデータ': 0, 'Dr品': 0, 'Dr情報': 0, 'Dr3': 0, 'Dr製品': 0, 'DrDTL': 0, 'Dr差別': 0, 'Dr化': 0, 'Drこと': 0, 'Dr先生': 0, '3知識': 0, '3薬': 0, '3TOV': 0, '3イン': 0, '3サイト': 0, '3競合': 0, '3コリン': 0, '3強化': 0, '3スキル': 0, '3データ': 0, '3品': 0, '3情報': 0, '3Dr': 0, '3製品': 0, '3DTL': 0, '3差別': 0, '3化': 0, '3こと': 0, '3先生': 0, '製品知識': 1, '製品薬': 0, '製品TOV': 0, '製品イン': 0, '製品サイト': 0, '製品競合': 0, '製品コリン': 0, '製品強化': 0, '製品スキル': 0, '製品データ': 0, '製品品': 0, '製品情報': 1, '製品Dr': 0, '製品3': 0, '製品DTL': 1, '製品差別': 0, '製品化': 0, '製品こと': 0, '製品先生': 0, 'DTL知識': 0, 'DTL薬': 0, 'DTLTOV': 0, 'DTLイン': 0, 'DTLサイト': 0, 'DTL競合': 0, 'DTLコリン': 0, 'DTL強化': 0, 'DTLスキル': 1, 'DTLデータ': 0, 'DTL品': 0, 'DTL情報': 0, 'DTLDr': 0, 'DTL3': 0, 'DTL製品': 0, 'DTL差別': 0, 'DTL化': 0, 'DTLこと': 0, 'DTL先生': 0, '差別知識': 0, '差別薬': 0, '差別TOV': 0, '差別イン': 0, '差別サイト': 0, '差別競合': 0, '差別コリン': 0, '差別強化': 0, '差別スキル': 0, '差別データ': 0, '差別品': 0, '差別情報': 0, '差別Dr': 0, '差別3': 0, '差別製品': 0, '差別DTL': 0, '差別化': 1, '差別こと': 0, '差別先生': 0, '化知識': 0, '化薬': 0, '化TOV': 1, '化イン': 0, '化サイト': 0, '化競合': 0, '化コリン': 0, '化強化': 0, '化スキル': 0, '化データ': 0, '化品': 0, '化情報': 0, '化Dr': 0, '化3': 0, '化製品': 0, '化DTL': 0, '化差別': 0, '化こと': 0, '化先生': 0, 'こと知識': 0, 'こと薬': 0, 'ことTOV': 0, 'ことイン': 0, 'ことサイト': 0, 'こと競合': 0, 'ことコリン': 0, 'こと強化': 0, 'ことスキル': 0, 'ことデータ': 0, 'こと品': 0, 'こと情報': 0, 'ことDr': 0, 'こと3': 0, 'こと製品': 0, 'ことDTL': 0, 'こと差別': 0, 'こと化': 0, 'こと先生': 0, '先生知識': 0, '先生薬': 0, '先生TOV': 0, '先生イン': 0, '先生サイト': 0, '先生競合': 0, '先生コリン': 0, '先生強化': 0, '先生スキル': 0, '先生データ': 0, '先生品': 0, '先生情報': 0, '先生Dr': 0, '先生3': 0, '先生製品': 0, '先生DTL': 0, '先生差別': 0, '先生化': 0, '先生こと': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "line_text = col15_sentence_text\n",
        "freq = Counter(y).most_common()\n",
        "print(freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCpTbHr8jA0m",
        "outputId": "60fc90e4-e914-4e7a-b398-236b2e3d2fa7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('知識薬', 1), ('知識TOV', 1), ('知識イン', 1), ('知識サイト', 1), ('知識競合', 1), ('知識コリン', 1), ('知識強化', 1), ('知識スキル', 1), ('知識データ', 1), ('知識品', 1), ('知識情報', 1), ('知識Dr', 1), ('知識3', 1), ('知識製品', 1), ('知識DTL', 1), ('知識差別', 1), ('知識化', 1), ('知識こと', 1), ('知識先生', 1), ('薬知識', 1), ('薬TOV', 1), ('薬イン', 1), ('薬サイト', 1), ('薬競合', 1), ('薬コリン', 1), ('薬強化', 1), ('薬スキル', 1), ('薬データ', 1), ('薬品', 1), ('薬情報', 1), ('薬Dr', 1), ('薬3', 1), ('薬製品', 1), ('薬DTL', 1), ('薬差別', 1), ('薬化', 1), ('薬こと', 1), ('薬先生', 1), ('TOV知識', 1), ('TOV薬', 1), ('TOVイン', 1), ('TOVサイト', 1), ('TOV競合', 1), ('TOVコリン', 1), ('TOV強化', 1), ('TOVスキル', 1), ('TOVデータ', 1), ('TOV品', 1), ('TOV情報', 1), ('TOVDr', 1), ('TOV3', 1), ('TOV製品', 1), ('TOVDTL', 1), ('TOV差別', 1), ('TOV化', 1), ('TOVこと', 1), ('TOV先生', 1), ('イン知識', 1), ('イン薬', 1), ('インTOV', 1), ('インサイト', 1), ('イン競合', 1), ('インコリン', 1), ('イン強化', 1), ('インスキル', 1), ('インデータ', 1), ('イン品', 1), ('イン情報', 1), ('インDr', 1), ('イン3', 1), ('イン製品', 1), ('インDTL', 1), ('イン差別', 1), ('イン化', 1), ('インこと', 1), ('イン先生', 1), ('サイト知識', 1), ('サイト薬', 1), ('サイトTOV', 1), ('サイトイン', 1), ('サイト競合', 1), ('サイトコリン', 1), ('サイト強化', 1), ('サイトスキル', 1), ('サイトデータ', 1), ('サイト品', 1), ('サイト情報', 1), ('サイトDr', 1), ('サイト3', 1), ('サイト製品', 1), ('サイトDTL', 1), ('サイト差別', 1), ('サイト化', 1), ('サイトこと', 1), ('サイト先生', 1), ('競合知識', 1), ('競合薬', 1), ('競合TOV', 1), ('競合イン', 1), ('競合サイト', 1), ('競合コリン', 1), ('競合強化', 1), ('競合スキル', 1), ('競合データ', 1), ('競合品', 1), ('競合情報', 1), ('競合Dr', 1), ('競合3', 1), ('競合製品', 1), ('競合DTL', 1), ('競合差別', 1), ('競合化', 1), ('競合こと', 1), ('競合先生', 1), ('コリン知識', 1), ('コリン薬', 1), ('コリンTOV', 1), ('コリンイン', 1), ('コリンサイト', 1), ('コリン競合', 1), ('コリン強化', 1), ('コリンスキル', 1), ('コリンデータ', 1), ('コリン品', 1), ('コリン情報', 1), ('コリンDr', 1), ('コリン3', 1), ('コリン製品', 1), ('コリンDTL', 1), ('コリン差別', 1), ('コリン化', 1), ('コリンこと', 1), ('コリン先生', 1), ('強化知識', 1), ('強化薬', 1), ('強化TOV', 1), ('強化イン', 1), ('強化サイト', 1), ('強化競合', 1), ('強化コリン', 1), ('強化スキル', 1), ('強化データ', 1), ('強化品', 1), ('強化情報', 1), ('強化Dr', 1), ('強化3', 1), ('強化製品', 1), ('強化DTL', 1), ('強化差別', 1), ('強化化', 1), ('強化こと', 1), ('強化先生', 1), ('スキル知識', 1), ('スキル薬', 1), ('スキルTOV', 1), ('スキルイン', 1), ('スキルサイト', 1), ('スキル競合', 1), ('スキルコリン', 1), ('スキル強化', 1), ('スキルデータ', 1), ('スキル品', 1), ('スキル情報', 1), ('スキルDr', 1), ('スキル3', 1), ('スキル製品', 1), ('スキルDTL', 1), ('スキル差別', 1), ('スキル化', 1), ('スキルこと', 1), ('スキル先生', 1), ('データ知識', 1), ('データ薬', 1), ('データTOV', 1), ('データイン', 1), ('データサイト', 1), ('データ競合', 1), ('データコリン', 1), ('データ強化', 1), ('データスキル', 1), ('データ品', 1), ('データ情報', 1), ('データDr', 1), ('データ3', 1), ('データ製品', 1), ('データDTL', 1), ('データ差別', 1), ('データ化', 1), ('データこと', 1), ('データ先生', 1), ('品知識', 1), ('品薬', 1), ('品TOV', 1), ('品イン', 1), ('品サイト', 1), ('品競合', 1), ('品コリン', 1), ('品強化', 1), ('品スキル', 1), ('品データ', 1), ('品情報', 1), ('品Dr', 1), ('品3', 1), ('品製品', 1), ('品DTL', 1), ('品差別', 1), ('品化', 1), ('品こと', 1), ('品先生', 1), ('情報知識', 1), ('情報薬', 1), ('情報TOV', 1), ('情報イン', 1), ('情報サイト', 1), ('情報競合', 1), ('情報コリン', 1), ('情報強化', 1), ('情報スキル', 1), ('情報データ', 1), ('情報品', 1), ('情報Dr', 1), ('情報3', 1), ('情報製品', 1), ('情報DTL', 1), ('情報差別', 1), ('情報化', 1), ('情報こと', 1), ('情報先生', 1), ('Dr知識', 1), ('Dr薬', 1), ('DrTOV', 1), ('Drイン', 1), ('Drサイト', 1), ('Dr競合', 1), ('Drコリン', 1), ('Dr強化', 1), ('Drスキル', 1), ('Drデータ', 1), ('Dr品', 1), ('Dr情報', 1), ('Dr3', 1), ('Dr製品', 1), ('DrDTL', 1), ('Dr差別', 1), ('Dr化', 1), ('Drこと', 1), ('Dr先生', 1), ('3知識', 1), ('3薬', 1), ('3TOV', 1), ('3イン', 1), ('3サイト', 1), ('3競合', 1), ('3コリン', 1), ('3強化', 1), ('3スキル', 1), ('3データ', 1), ('3品', 1), ('3情報', 1), ('3Dr', 1), ('3製品', 1), ('3DTL', 1), ('3差別', 1), ('3化', 1), ('3こと', 1), ('3先生', 1), ('製品知識', 1), ('製品薬', 1), ('製品TOV', 1), ('製品イン', 1), ('製品サイト', 1), ('製品競合', 1), ('製品コリン', 1), ('製品強化', 1), ('製品スキル', 1), ('製品データ', 1), ('製品品', 1), ('製品情報', 1), ('製品Dr', 1), ('製品3', 1), ('製品DTL', 1), ('製品差別', 1), ('製品化', 1), ('製品こと', 1), ('製品先生', 1), ('DTL知識', 1), ('DTL薬', 1), ('DTLTOV', 1), ('DTLイン', 1), ('DTLサイト', 1), ('DTL競合', 1), ('DTLコリン', 1), ('DTL強化', 1), ('DTLスキル', 1), ('DTLデータ', 1), ('DTL品', 1), ('DTL情報', 1), ('DTLDr', 1), ('DTL3', 1), ('DTL製品', 1), ('DTL差別', 1), ('DTL化', 1), ('DTLこと', 1), ('DTL先生', 1), ('差別知識', 1), ('差別薬', 1), ('差別TOV', 1), ('差別イン', 1), ('差別サイト', 1), ('差別競合', 1), ('差別コリン', 1), ('差別強化', 1), ('差別スキル', 1), ('差別データ', 1), ('差別品', 1), ('差別情報', 1), ('差別Dr', 1), ('差別3', 1), ('差別製品', 1), ('差別DTL', 1), ('差別化', 1), ('差別こと', 1), ('差別先生', 1), ('化知識', 1), ('化薬', 1), ('化TOV', 1), ('化イン', 1), ('化サイト', 1), ('化競合', 1), ('化コリン', 1), ('化強化', 1), ('化スキル', 1), ('化データ', 1), ('化品', 1), ('化情報', 1), ('化Dr', 1), ('化3', 1), ('化製品', 1), ('化DTL', 1), ('化差別', 1), ('化こと', 1), ('化先生', 1), ('こと知識', 1), ('こと薬', 1), ('ことTOV', 1), ('ことイン', 1), ('ことサイト', 1), ('こと競合', 1), ('ことコリン', 1), ('こと強化', 1), ('ことスキル', 1), ('ことデータ', 1), ('こと品', 1), ('こと情報', 1), ('ことDr', 1), ('こと3', 1), ('こと製品', 1), ('ことDTL', 1), ('こと差別', 1), ('こと化', 1), ('こと先生', 1), ('先生知識', 1), ('先生薬', 1), ('先生TOV', 1), ('先生イン', 1), ('先生サイト', 1), ('先生競合', 1), ('先生コリン', 1), ('先生強化', 1), ('先生スキル', 1), ('先生データ', 1), ('先生品', 1), ('先生情報', 1), ('先生Dr', 1), ('先生3', 1), ('先生製品', 1), ('先生DTL', 1), ('先生差別', 1), ('先生化', 1), ('先生こと', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordstring=col15_sentence_text\n",
        "wordlist = y\n",
        "\n",
        "wordfreq = []\n",
        "for w in wordlist:\n",
        "    wordfreq.append(wordlist.count(w))\n",
        "\n",
        "print(\"String\\n\" + wordstring +\"\\n\")\n",
        "print(\"List\\n\" + str(wordlist) + \"\\n\")\n",
        "print(\"Frequencies\\n\" + str(wordfreq) + \"\\n\")\n",
        "print(\"Pairs\\n\" + str(list(zip(wordlist, wordfreq))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXNpKW6djfmU",
        "outputId": "28177b6b-677e-4871-e893-99cbef715833"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "String\n",
            "もっとベタニスベオーバを学ぶ特になし他剤理解しTOV継続訴求不安は無いですインサイトの深堀が重要であることは着任時から重要と思い指導している。しかし、現場で出来ているかと言えば、出来ていないMRもいる。\n",
            "今回のFFTでインサイトの深堀が重要だというのはMRに伝わったと感じる。しかし、これが現場で使うにはもっとトレーニングが必要であると感じているしっかり話し込みが出来た先生には、TOVの効果面や安全性(FORTA等)はお伝えできた。課題は、面会が困難で短時間面会Drや不面Drへの対策が不十分なこと。β3を第一選択、抗コリンを第二選択にしていて、OABSSや排尿日誌では診療時間が多く取られてしまうので、問診だけで切迫性尿失禁の有無を聞いている先生がいます。そういった忙しい先生へ、トビエースを服用する患者さん像が一言で分かるようなフレーズが欲しい安全性に対する質問へのオブジェクションハンドリングおむつケアなどの知識飽きられない工夫が必要。\n",
            "Drのインサイトを得意先別の攻略に活かす事。苦手なインサイトを把握するスキルを更に身に付けていきたいDr.ニーズの把握、位置付けの確立特になし抗コリン薬を第一選択で処方すべき患者像をより具体的に提示できるスライド・データがあると良い。疾患・製品知識をさらに強化したいTOVの臨床試験も豊富にあるので、各臨床試験の細かい部分は定期的に復習したいと思います。TOVのUUIに関する試験を明確にしたい。疾患スキルGEの浸食を妨げることは国策に抵抗する事にはならないのか？特になしTOVの処方経験がないDｒ.には、抗コリン剤のなかでの位置づけがさらに難しい場合もあると感じた。競合品情報特にありません。抗コリン薬、B3受容体作動薬の使い分けをされている先生のインサイトを探るスキルを強化したい。競合品、ベータ薬の訴求ポイントやDTL内容を知りたいです。抗コリンとβ3の使い分けでTOVのお役に立てる症例には女性を意識させたほうがいいのではと感じました。資材を予定通りリリースしていただければ幸いです。インサイトを捉えるトレーニングを実践で積み強化したいβとの差別化本日実施したインサイト確認の徹底β作動薬とのすみわけどうつけていくか、TOVはこう言った症例、β作動薬はこう言った症例と明確なポジションを提示出来たらよいと考えています。理解が深まったが実践練習が必要と感じたのでチームミーティング等で復習したいと思います。副作用対策スライドが欲しい。新データがあればご教授いただきたいです。TOV市販後調査の結果も早期に共有いただきたいです。過活動膀胱と他疾患との関係について知識を深めたい。特に癌領域。作用機序の差別化徹底坑コリン剤比較について製品知識インサイトからの深堀提案スキル松川先生のBPH合併試験のような小さな試験でもいいので、新しいデータを出して頂きたい。ベオーバとの差別化ベシケアとの差別化からの抗コリンFast確立スキル関連情報で前立腺肥大症についての知識が不足している特になし様々なプロービング方法特になし短い面談となった際でも適切なDSPを用いてインパクトが残るワンポイントメッセージが展開出来るよう強化したい。特にない今月のFFTの様に製品の知識にプラスして営業として必要なスキルや考え方についての研修があれば嬉しいです。不安なな点は特になし。クオリティーコールにあるアスキングを強化して、DTLスキルを高めたい製品知識製品多くの泌尿器科専門医が特に夜間頻尿を訴えるケースにはβ3を使うといった流れが出来つつあります競合品情報今回のFFTを受講して、更にベシケアにしっかりとTGを絞っていく必要があると感じました。疾患に関する知識強豪との差別化をより深く理解します。他社情報他剤との違いについて特約店MSと協業できる機会の創出、不安的な事はないのです。どうしても他抗コリン薬と比較したDTLをしてしまうのでTOVの特性のみを伝える虎の巻の様なサマリーノートは知識を確認するのにとても役に立ちます。特にベオーバのデータはあまり見たことが無かったのですプロービングスキル向上Drの聞く耳がもってもらえるかが不安。UUIの示せる国内データが欲しい副作用への対策　競合品情報を強化したいと考えています現場でDTLする話し言葉で話して欲しい。その中で上手な言い回しを勉強させて欲しいDTLスキル面を更に強化していきたい。他社品のUUIに対するデータ特になしDTLスキルの向上β3作動薬に関する薬剤特性の深い理解。製品の情報提供ができているため、しっかりクロージング、処方依頼を強化したい。虎の巻をじっくりと読み込みたい。特になしなし他剤と差別化TOVの副作用が思っていたより多いねと言われた先生への対応。クロージング強化TOVのβ３作動薬との併用データ競合の試験を再度復習したい対抗品が選択されている理由の把握と対策が有効ではない。専門医での評価を高める対策をとることが大事ではないでしょうか？競合品情報特になしβ3作動薬を1stに処方しているDr.に対して、自信を持ってアプローチする方法を身につけさせたい。\n",
            "ベシケアが根強いのでその対策β3作動薬に関するデータなど内科の先生はやはり、β3を多く使われてる先生が多い。セカンドチョイスの割合を広げていく点にまだ不安があるDr.インサイトと製品DTLの当てはめを意識してDTLしていきます。差別化排尿機能障害の診療報酬について非薬物療法の知識の強化することで薬物導入について的確なDTLが可能になると思う。UUIの主要評価項目についてのDTLを強化します競合品情報競合製品情報競合の製品知識UUIという言葉はDRとMRの間では通じるが、患者さんには浸透していないので、UUIという言葉の患者さん向けの啓発をお願いしたいです。Drインサイトを捉えたdtl泌尿器科専門医に対して男性BPH合併OAB患者に対する治療などについてもディスカッション出来るよう知識武装したい疾患の知識βのガイドラインでの位置づけ競合品（β3）の知識（データ）等の向上特になしコロナの中でOAB市場やDrの考え方がどう変わったのかを知りたいと思いました。より幅広い疾患の知識が欲しい。泌尿器科領域の疾患　OAB以外の周辺知識（ONC領域抗がん剤等）を向上する事で、専門医との話題に活かせれれば、関係構築からTOVに広がるのではないでしょうか？なし製品知識他OAB治療薬（特に抗コリン薬）との差別化につながるデータ・知識の面抗コリンとβ3の作用機序の違いをコンパクトにご紹介することβとの比較アスキングのスキルアップを図る競合の動きを掴みたい有効性と安全性のバランス訴求新しい話題がないため、ネタに困る効果が強過ぎると言われた時の対処医師のニーズを引き出すスキル競合品情報　ベオーバ　UUIデータなどTOVの夜間頻尿への効果について過活動膀胱の薬剤の添付文書上の違いと特徴を明確に理解した上でTOV特性を伝えるDrの合意形成のアグリーまでの確約がまだ不安。インサイトをとらえるフレーズは多ければ多いほどいいと思いますトビエース以外は後発がでてしまい、割高と思われないか虎の巻はあるが、他の抗コリン薬と差別化できる、競合品情報を強化したい。とくになしインサイトを引き出せれば効果的だとは思うがそう簡単ではないという印象を受けた。しかしながらインサイトを捉えようとする行動は誰でもいつでもできることなのでチャレンジをさせたいと思う。CMTEPPVや供給案内もありTGに対してメッセージを届け切れていないMRが多いので稼働計画をリプランし抗コリン薬の中での位置づけを確認し積極的に訴求したい。特にございません\n",
            "\n",
            "List\n",
            "['知識薬', '知識TOV', '知識イン', '知識サイト', '知識競合', '知識コリン', '知識強化', '知識スキル', '知識データ', '知識品', '知識情報', '知識Dr', '知識3', '知識製品', '知識DTL', '知識差別', '知識化', '知識こと', '知識先生', '薬知識', '薬TOV', '薬イン', '薬サイト', '薬競合', '薬コリン', '薬強化', '薬スキル', '薬データ', '薬品', '薬情報', '薬Dr', '薬3', '薬製品', '薬DTL', '薬差別', '薬化', '薬こと', '薬先生', 'TOV知識', 'TOV薬', 'TOVイン', 'TOVサイト', 'TOV競合', 'TOVコリン', 'TOV強化', 'TOVスキル', 'TOVデータ', 'TOV品', 'TOV情報', 'TOVDr', 'TOV3', 'TOV製品', 'TOVDTL', 'TOV差別', 'TOV化', 'TOVこと', 'TOV先生', 'イン知識', 'イン薬', 'インTOV', 'インサイト', 'イン競合', 'インコリン', 'イン強化', 'インスキル', 'インデータ', 'イン品', 'イン情報', 'インDr', 'イン3', 'イン製品', 'インDTL', 'イン差別', 'イン化', 'インこと', 'イン先生', 'サイト知識', 'サイト薬', 'サイトTOV', 'サイトイン', 'サイト競合', 'サイトコリン', 'サイト強化', 'サイトスキル', 'サイトデータ', 'サイト品', 'サイト情報', 'サイトDr', 'サイト3', 'サイト製品', 'サイトDTL', 'サイト差別', 'サイト化', 'サイトこと', 'サイト先生', '競合知識', '競合薬', '競合TOV', '競合イン', '競合サイト', '競合コリン', '競合強化', '競合スキル', '競合データ', '競合品', '競合情報', '競合Dr', '競合3', '競合製品', '競合DTL', '競合差別', '競合化', '競合こと', '競合先生', 'コリン知識', 'コリン薬', 'コリンTOV', 'コリンイン', 'コリンサイト', 'コリン競合', 'コリン強化', 'コリンスキル', 'コリンデータ', 'コリン品', 'コリン情報', 'コリンDr', 'コリン3', 'コリン製品', 'コリンDTL', 'コリン差別', 'コリン化', 'コリンこと', 'コリン先生', '強化知識', '強化薬', '強化TOV', '強化イン', '強化サイト', '強化競合', '強化コリン', '強化スキル', '強化データ', '強化品', '強化情報', '強化Dr', '強化3', '強化製品', '強化DTL', '強化差別', '強化化', '強化こと', '強化先生', 'スキル知識', 'スキル薬', 'スキルTOV', 'スキルイン', 'スキルサイト', 'スキル競合', 'スキルコリン', 'スキル強化', 'スキルデータ', 'スキル品', 'スキル情報', 'スキルDr', 'スキル3', 'スキル製品', 'スキルDTL', 'スキル差別', 'スキル化', 'スキルこと', 'スキル先生', 'データ知識', 'データ薬', 'データTOV', 'データイン', 'データサイト', 'データ競合', 'データコリン', 'データ強化', 'データスキル', 'データ品', 'データ情報', 'データDr', 'データ3', 'データ製品', 'データDTL', 'データ差別', 'データ化', 'データこと', 'データ先生', '品知識', '品薬', '品TOV', '品イン', '品サイト', '品競合', '品コリン', '品強化', '品スキル', '品データ', '品情報', '品Dr', '品3', '品製品', '品DTL', '品差別', '品化', '品こと', '品先生', '情報知識', '情報薬', '情報TOV', '情報イン', '情報サイト', '情報競合', '情報コリン', '情報強化', '情報スキル', '情報データ', '情報品', '情報Dr', '情報3', '情報製品', '情報DTL', '情報差別', '情報化', '情報こと', '情報先生', 'Dr知識', 'Dr薬', 'DrTOV', 'Drイン', 'Drサイト', 'Dr競合', 'Drコリン', 'Dr強化', 'Drスキル', 'Drデータ', 'Dr品', 'Dr情報', 'Dr3', 'Dr製品', 'DrDTL', 'Dr差別', 'Dr化', 'Drこと', 'Dr先生', '3知識', '3薬', '3TOV', '3イン', '3サイト', '3競合', '3コリン', '3強化', '3スキル', '3データ', '3品', '3情報', '3Dr', '3製品', '3DTL', '3差別', '3化', '3こと', '3先生', '製品知識', '製品薬', '製品TOV', '製品イン', '製品サイト', '製品競合', '製品コリン', '製品強化', '製品スキル', '製品データ', '製品品', '製品情報', '製品Dr', '製品3', '製品DTL', '製品差別', '製品化', '製品こと', '製品先生', 'DTL知識', 'DTL薬', 'DTLTOV', 'DTLイン', 'DTLサイト', 'DTL競合', 'DTLコリン', 'DTL強化', 'DTLスキル', 'DTLデータ', 'DTL品', 'DTL情報', 'DTLDr', 'DTL3', 'DTL製品', 'DTL差別', 'DTL化', 'DTLこと', 'DTL先生', '差別知識', '差別薬', '差別TOV', '差別イン', '差別サイト', '差別競合', '差別コリン', '差別強化', '差別スキル', '差別データ', '差別品', '差別情報', '差別Dr', '差別3', '差別製品', '差別DTL', '差別化', '差別こと', '差別先生', '化知識', '化薬', '化TOV', '化イン', '化サイト', '化競合', '化コリン', '化強化', '化スキル', '化データ', '化品', '化情報', '化Dr', '化3', '化製品', '化DTL', '化差別', '化こと', '化先生', 'こと知識', 'こと薬', 'ことTOV', 'ことイン', 'ことサイト', 'こと競合', 'ことコリン', 'こと強化', 'ことスキル', 'ことデータ', 'こと品', 'こと情報', 'ことDr', 'こと3', 'こと製品', 'ことDTL', 'こと差別', 'こと化', 'こと先生', '先生知識', '先生薬', '先生TOV', '先生イン', '先生サイト', '先生競合', '先生コリン', '先生強化', '先生スキル', '先生データ', '先生品', '先生情報', '先生Dr', '先生3', '先生製品', '先生DTL', '先生差別', '先生化', '先生こと']\n",
            "\n",
            "Frequencies\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-e62fbc4ff918>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"List\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Frequencies\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordfreq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pairs\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordfreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "text = sentences[5]\n",
        "    # Tokenize\n",
        "# text = ' '.join(jieba.cut(text))\n",
        "text_tokens=text.split()\n",
        "print(text_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvBw9JMxBj5-",
        "outputId": "86f0152f-2bfe-4ebd-def8-26c5dc5fc3d5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['しっかり話し込みが出来た先生には、TOVの効果面や安全性(FORTA等)はお伝えできた。課題は、面会が困難で短時間面会Drや不面Drへの対策が不十分なこと。']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "most_common_single_words=word_freq(text,n=20)\n",
        "print(most_common_single_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pwdN8RAD1oJ",
        "outputId": "84f93d5b-59c6-4f80-bc87-a3847ec98e39"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'面': 4, 'が': 3, 'は': 3, 'し': 2, 'た': 2, '、': 2, 'T': 2, 'O': 2, 'の': 2, 'や': 2, 'で': 2, '。': 2, '会': 2, 'D': 2, 'r': 2, '不': 2, 'っ': 1, 'か': 1, 'り': 1, '話': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UExF0BOe_k1Q",
        "outputId": "d8b95d09-c7c2-4cb4-856d-847ea87f366a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "def word_cloud(text_list):\n",
        "\n",
        "    # WordCloud\n",
        "    wc = WordCloud(max_words=2000,\n",
        "                max_font_size=40,\n",
        "                font_path='./fonts/simhei.ttf',\n",
        "                background_color='white',\n",
        "                random_state=42,\n",
        "                relative_scaling=0)\n",
        "\n",
        "    wc.generate(text_list)\n",
        "    # Plot\n",
        "    plt.figure()\n",
        "    plt.axis('off')\n",
        "    plt.imshow(wc)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "iZ-_87h5uVYJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#英文demo\n",
        "word_cloud(contents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4i3FIGOuXKp",
        "outputId": "a2485216-9dd8-4ba6-816d-7369b91bb8aa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-4a016bec1262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#英文demo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword_cloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-e709dbca7a40>\u001b[0m in \u001b[0;36mword_cloud\u001b[0;34m(text_list)\u001b[0m\n\u001b[1;32m     12\u001b[0m                 relative_scaling=0)\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mwc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \"\"\"\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \"\"\"\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mprocess_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0mregexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregexp\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregexp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mr\"\\w[\\w']+\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m         \u001b[0;31m# remove stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/re.py\u001b[0m in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "m = tagger.parseToNode(contents)\n",
        "\n",
        "keywords_rm_stopwords = []\n",
        "\n",
        "while m:\n",
        "    if m.feature.split(',')[0] == '名詞':\n",
        "        keywords.append(m.surface)\n",
        "    m = m.next\n",
        "\n",
        "print(keywords_rm_stopwords)"
      ],
      "metadata": {
        "id": "Uk-M6vw93YRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(keywords_rm_stopwords))"
      ],
      "metadata": {
        "id": "iZxl5ita4oyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import MeCab\n",
        "\n",
        "sentence = \"AWSの有名なサービスにAmazon Elastic Compute Cloud (EC2) とAmazon Simple Storage Service (S3) がある。これまでのクライアントが保有していた物理的なサーバファームと比較してAWSは大規模な計算処理能力を速やかに提供出来ることが強みである。\"\n",
        "tagger = MeCab.Tagger(ipadic.MECAB_ARGS)\n",
        "t = MeCab.Tagger(ipadic.MECAB_ARGS)\n",
        "t.parse('')\n",
        "m = t.parseToNode(sentence)\n",
        "\n",
        "keywords = []\n",
        "\n",
        "while m:\n",
        "    if m.feature.split(',')[0] == '名詞':\n",
        "        keywords.append(m.surface)\n",
        "    m = m.next\n",
        "\n",
        "print(keywords)"
      ],
      "metadata": {
        "id": "MQ-3u8nCxWNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import MeCab\n",
        "import ipadic\n",
        "tagger = MeCab.Tagger('-Owakati')\n",
        "\n",
        "print(tagger.parse(\"図書館にいた事がバレた\"))"
      ],
      "metadata": {
        "id": "deeQoyTCrzp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(MeCab.Tagger)"
      ],
      "metadata": {
        "id": "Ccv3nqqFuJpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "33f2bjt_vYu4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}